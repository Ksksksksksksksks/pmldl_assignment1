services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../code:/opt/airflow/code
      - ../data:/opt/airflow/data
      - ../:/opt/airflow
#    user: "50000:0"
    depends_on:
      - postgres
    entrypoint: /bin/bash
    command:
      - -c
      - |
        until pg_isready -h postgres -p 5432; do
          echo "Waiting for Postgres..."
          sleep 2
        done
        airflow db init && \
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com

  webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../code:/opt/airflow/code
      - ../data:/opt/airflow/data
      - ../:/opt/airflow
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8080:8080"
    command: airflow webserver
    user: "50000:0"

  scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../code:/opt/airflow/code
      - ../data:/opt/airflow/data
      - ../:/opt/airflow
      - /var/run/docker.sock:/var/run/docker.sock
    command: airflow scheduler
    user: "50000:0"

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.17.2
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/opt/airflow/mlruns
    command: >
      mlflow server 
      --backend-store-uri sqlite:///opt/airflow/mlruns/mlflow.db
      --default-artifact-root /opt/airflow/mlruns 
      --host 0.0.0.0 
      --port 5000

#  model_api:
#    build:
#      context: ../code/deployment/api
#      dockerfile: Dockerfile.api
#    volumes:
#      - ../:/opt/airflow
#    ports:
#      - "8000:8000"
#    restart: "no"
#    profiles: ["manual"]
#
#  app:
#    build:
#      context: ../code/deployment/app
#      dockerfile: Dockerfile.app
#    volumes:
#      - ../:/opt/airflow
#    ports:
#      - "8501:8501"
#    restart: "no"
#    depends_on:
#      - model_api
#    profiles: ["manual"]

volumes:
  postgres-db-volume:
